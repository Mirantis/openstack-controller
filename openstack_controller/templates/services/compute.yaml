#apiVersion: lcm.mirantis.com/v1alpha1
#kind: HelmBundle

{%- set service = 'nova' %}
{%- set components_with_dedicated_messaging = spec.get('features', {}).get('messaging', {}).get('components_with_dedicated_messaging', []) %}
{%- set stacklight_enabled = spec.get('features', {}).get('stacklight', {}).get('enabled', False) %}
{%- set notification_topics = ['notifications'] %}
{%- do notification_topics.append('stacklight_notifications') if stacklight_enabled %}
{%- set neutron_backend = spec.features.neutron.get('backend', 'ml2') %}
{%- set baremetal_enabled = 'baremetal' in spec.features.services %}
{%- set node_specific = {} %}
{%- set overrides = namespace(enabled=false) %}
{%- for label, node_features in spec.get("nodes", {}).items() %}
  {%- if "nova" in node_features.get("features", {}).keys() %}
    {% set overrides.enabled = true %}
  {%- endif  %}
  {%- if node_features.get("features", {}).get("neutron", {}).get("sriov", {}).get("enabled", false) %}
    {% set overrides.enabled = true %}
  {%- endif  %}
  {%- if node_features.get("features", {}) %}
    {%- do node_specific.update({label: node_features.features}) %}
  {%- endif %}
{%- endfor %}

{%- set signature = spec.get('features', {}).get('glance', {}).get("signature", {"enabled": false}) %}

{%- set ceph_enabled = spec.get('features', {}).get('nova', {}).get('images', {}).get('backend') == 'ceph' or spec.get('features', {}).get('cinder', {}).get('volume', {}).get('backend') == 'ceph' %}
{%- set ephemeral_encryption = spec.get('features', {}).get('nova', {}).get('images', {}).get("encryption", {}) %}
{%- set nova_db_cleanup = spec.get('features', {}).get('database', {}).get('cleanup', {}).get('nova', {'enabled': true}) %}

spec:
  releases:
{%- if 'compute' in components_with_dedicated_messaging %}
  - name: openstack-nova-rabbitmq
    chart: {{spec.common.infra.repo}}/rabbitmq
    values:
{% include 'base/_rabbitmq_images.yaml' %}
  {%- if stacklight_enabled %}
      monitoring:
        prometheus:
          enabled: true
  {%- endif %}
      pod:
        replicas:
          server: 1
        probes:
          server:
            rabbitmq:
              readiness:
                periodSeconds: 60
                timeoutSeconds: 30
              liveness:
                periodSeconds: 60
                timeoutSeconds: 30
      manifests:
        network_policy: false
        job_users_create: true
      volume:
        enabled: false
      endpoints:
        cluster_domain_suffix: {{ spec.internal_domain_name }}
{% include 'base/_messaging_dedicated.yaml' %}
      conf:
        users:
          nova:
            auth:
              service_user:
                username: {{ credentials.messaging.user.username }}
                password: {{ credentials.messaging.user.password }}
            path: /nova
        aux_conf:
          policies:
          - vhost: nova
            name: default-policy
            pattern: '^(?!amq\.).*'
            definition:
              message-ttl: 120000
          - vhost: nova
            name: results_expire
            pattern: '^results\.'
            definition:
              expires: 3600000
            priority: 1
          - vhost: nova
            name: tasks_expire
            pattern: '^tasks\.'
            definition:
              expires: 3600000
            priority: 1
  {%- if stacklight_enabled %}
        prometheus_exporter:
          rabbit_exporters: "overview,exchange,node"
  {%- endif %}
{%- endif %}
  - name: openstack-libvirt
    chart: {{spec.common.infra.repo}}/libvirt
    values:
      images:
        tags:
{%- for image in ["image_repo_sync",
                 "libvirt",
                 "ceph_config_helper",
                 "dep_check",] %}
        {%- if image in images %}
          {{ image }}: {{ images[image] }}
        {%- endif %}
{%- endfor %}
      manifests:
        network_policy: false
{%- if ceph_enabled %}
      ceph_client:
        configmap: rook-ceph-config
        user_secret_name: {{ ceph.nova.secrets }}
{%- endif %}
      conf:
        ceph:
{%- if ceph_enabled %}
          enabled: true
          cinder:
            user: {{ ceph.nova.username }}
            keyring: {{ ceph.nova.keyring }}
{%- else %}
          enabled: false
{%- endif %}
        libvirt:
          listen_addr: 0.0.0.0
        qemu:
          security_driver: apparmor
      {%- if neutron_backend == 'tungstenfabric' %}
      network:
        backend: []
      {%- endif %}
{%- if spec.openstack_version in ['queens', 'rocky', 'stein', 'train'] %}
      # in libvirt 4.0.0 there is no support of admin protocol to check virtlogd health
      pod:
        probes:
          libvirt:
            virtlogd:
              readiness:
                enabled: false
              liveness:
                enabled: false
{%- endif %}
{%- if spec.get('migration', {}).get('nova', {}).get('deploy_main_service', True) %}
  - name: openstack-nova
    chart: {{spec.common.openstack.repo}}/nova
    values:
      images:
        tags:
{%- for image in [
    "nova_cell_setup_init",
    "nova_placement",
    "nova_compute_ironic",
    "nova_db_sync",
    "nova_db_sync_online",
    "nova_db_sync_db",
    "nova_db_sync_api",
    "nova_db_purge",
    "db_drop",
    "bootstrap",
    "image_repo_sync",
    "nova_compute_ssh",
    "ks_endpoints",
    "nova_api",
    "db_init",
    "nova_conductor",
    "dep_check",
    "nova_compute",
    "nova_novncproxy",
    "ks_user",
    "ks_service",
    "nova_spiceproxy",
    "nova_scheduler",
    "nova_novncproxy_assets",
    "nova_spiceproxy_assets",
    "rabbit_init",
    "nova_cell_setup",
    "nova_consoleauth",
    "test",
    "nova_service_cleaner",] %}
        {%- if image in images %}
          {{ image }}: {{ images[image] }}
        {%- endif %}
{%- endfor %}
      labels:
        agent:
          compute_ironic:
            node_selector_key: openstack-control-plane
            node_selector_value: enabled
      # NODE SPECIFIC START
      {%- if overrides.enabled %}
      overrides:
        nova_compute:
          labels:
        {%- for label, override in node_specific.items() %}
          {%- set neutron_override = override.get("neutron", {}) %}
          {%- set nova_override = override.get("nova", {}) %}
          {%- if neutron_override.get("sriov", {}).get("enabled", False) or nova_override %}
            {{ label }}:
          {%- endif %}
          {%- if neutron_override.get("sriov", {}).get("enabled", False) %}
              values:
                network:
                  backend:
                    - sriovnicswitch
                  interface:
                    sriov: {{ neutron_override.sriov.nics }}
          {%- endif %}
          {%- if nova_override.get("images", {}).get("backend") or nova_override.get('live_migration_interface') %}
                conf:
            {%- if nova_override.get("images", {}).get("backend") %}
                  nova:
                    libvirt:
              {%- if nova_override.images.backend == 'ceph' %}
                      images_type: rbd
              {%- elif nova_override.images.backend == 'local' %}
                      images_type: qcow2
              {%- elif nova_override.images.backend == 'lvm' %}
                      images_type: lvm
                      images_volume_group: {{ nova_override.images.get('lvm', {}).get("volume_group", "nova-vol") }}
                {%- if nova_override.get("images", {}).get("encryption", {}).get("enabled", false) %}
                    ephemeral_storage_encryption:
                      enabled: true
                      cipher: {{ nova_override.images.encryption.get("cipher", "aes-xts-plain64") }}
                      key_size: {{ nova_override.images.encryption.get("key_size", 256) }}
                {%- endif %}
              {%- endif %}
            {%- endif %}
            {%- if nova_override.get('live_migration_interface') %}
                  libvirt:
                    live_migration_interface: {{ nova_override.live_migration_interface }}
                  hypervisor:
                    host_interface: {{ nova_override.live_migration_interface }}
            {%- endif %}
          {%- endif %}

        {%- endfor %}
        {%- endif %}
      # NODE SPECIFIC END
      pod:
        # NOTE(ohryhorov): use_fqdn is disabled not to use FQDN
        # in service hostnames
        use_fqdn:
          compute: false
        # NOTE(vsaienko): don't use host networking to be able to
        # update pods with surge (when node hostport is used)
        useHostNetwork:
          novncproxy: false
        probes:
          rpc_timeout: 30
          rpc_retries: 2
          compute:
            default:
              liveness:
                enabled: True
                params:
                  initialDelaySeconds: 0
                  periodSeconds: 50
                  timeoutSeconds: 40
              readiness:
                enabled: True
                params:
                  initialDelaySeconds: 0
                  periodSeconds: 50
                  timeoutSeconds: 40
          conductor:
            default:
              liveness:
                enabled: True
                params:
                  initialDelaySeconds: 0
                  periodSeconds: 50
                  timeoutSeconds: 40
              readiness:
                enabled: True
                params:
                  initialDelaySeconds: 0
                  periodSeconds: 50
                  timeoutSeconds: 40
          consoleauth:
            default:
              liveness:
                enabled: True
                params:
                  initialDelaySeconds: 0
                  periodSeconds: 50
                  timeoutSeconds: 40
              readiness:
                enabled: True
                params:
                  initialDelaySeconds: 0
                  periodSeconds: 50
                  timeoutSeconds: 40
          novncproxy:
            default:
              liveness:
                enabled: True
                params:
                  initialDelaySeconds: 0
              readiness:
                enabled: True
                params:
                  initialDelaySeconds: 0
          scheduler:
            default:
              liveness:
                enabled: True
                params:
                  initialDelaySeconds: 0
                  periodSeconds: 50
                  timeoutSeconds: 40
              readiness:
                enabled: True
                params:
                  initialDelaySeconds: 0
                  periodSeconds: 50
                  timeoutSeconds: 40
        replicas:
          osapi: 3
          placement: 3
      dependencies:
        static:
          db_init:
            jobs:
              - openstack-mariadb-cluster-wait
      manifests:
        cron_job_db_purge: {{ nova_db_cleanup.enabled }}
        network_policy: false
        job_rabbit_init: false
{%- if spec.openstack_version not in ['queens', 'rocky'] %}
        deployment_consoleauth: false
# Since Rocky placemnt is deployed as separate service
        deployment_placement: false
        ingress_placement: false
        job_db_init_placement: false
        job_ks_placement_endpoints: false
        job_ks_placement_service: false
        job_ks_placement_user: false
        pdb_placement: false
        secret_keystone_placement: false
        service_ingress_placement: false
        service_placement: false
{%- endif %}
        secret_ca_bundle: true
      {%- if baremetal_enabled %}
        statefulset_compute_ironic: true
      {%- endif %}
      endpoints:
        cluster_domain_suffix: {{ spec.internal_domain_name }}
{% include 'base/_admin_identity.yaml' %}
{% include 'base/_cache.yaml' %}
        oslo_db:
          auth:
            admin:
              username: {{ admin_creds.database.username }}
              password: {{ admin_creds.database.password }}
            nova:
              username: {{ credentials.database.user.username }}
              password: {{ credentials.database.user.password }}
        oslo_db_api:
          auth:
            admin:
              username: {{ admin_creds.database.username }}
              password: {{ admin_creds.database.password }}
            nova:
              username: {{ credentials.database.user.username }}
              password: {{ credentials.database.user.password }}
        oslo_db_cell0:
          auth:
            admin:
              username: {{ admin_creds.database.username }}
              password: {{ admin_creds.database.password }}
            nova:
              username: {{ credentials.database.user.username }}
              password: {{ credentials.database.user.password }}
{%- if 'compute' in components_with_dedicated_messaging %}
{% include 'base/_messaging_dedicated.yaml' %}
{%- else %}
{% include 'base/_messaging_shared.yaml' %}
{%- endif %}
{% include 'base/_notifications.yaml' %}
        compute:
          host_fqdn_override:
            public:
              host: nova.{{ spec.public_domain_name }}
              tls:
                ca: |
{{ spec.features.ssl.public_endpoints.ca_cert | indent( width=18, first=True) }}
                crt: |
{{ spec.features.ssl.public_endpoints.api_cert | indent( width=18, first=True) }}
                key: |
{{ spec.features.ssl.public_endpoints.api_key | indent( width=18, first=True) }}
          hosts:
            admin:
              host: nova-api
            default: nova
            internal: nova-api
            public:
              host: nova
              tls:
                ca: |
{{ spec.features.ssl.public_endpoints.ca_cert | indent( width=18, first=True) }}
                crt: |
{{ spec.features.ssl.public_endpoints.api_cert | indent( width=18, first=True) }}
                key: |
{{ spec.features.ssl.public_endpoints.api_key | indent( width=18, first=True) }}
          port:
            api:
              admin: 8774
              default: 80
              internal: 8774
              public: 443
          scheme:
            default: http
            public: https
        placement:
          host_fqdn_override:
            public:
              host: placement.{{ spec.public_domain_name }}
              tls:
                ca: |
{{ spec.features.ssl.public_endpoints.ca_cert | indent( width=18, first=True) }}
                crt: |
{{ spec.features.ssl.public_endpoints.api_cert | indent( width=18, first=True) }}
                key: |
{{ spec.features.ssl.public_endpoints.api_key | indent( width=18, first=True) }}
          hosts:
            admin:
              host: placement-api
            default: placement
            internal: placement-api
            public:
              host: placement
              tls:
                ca: |
{{ spec.features.ssl.public_endpoints.ca_cert | indent( width=18, first=True) }}
                crt: |
{{ spec.features.ssl.public_endpoints.api_cert | indent( width=18, first=True) }}
                key: |
{{ spec.features.ssl.public_endpoints.api_key | indent( width=18, first=True) }}
          port:
            api:
              admin: 8778
              default: 80
              internal: 8778
              public: 443
          scheme:
            default: http
            public: https
        compute_novnc_proxy:
          host_fqdn_override:
            public:
              host: novncproxy.{{ spec.public_domain_name }}
              tls:
                ca: |
{{ spec.features.ssl.public_endpoints.ca_cert | indent(width=18, first=True) }}
                crt: |
{{ spec.features.ssl.public_endpoints.api_cert | indent(width=18, first=True) }}
                key: |
{{ spec.features.ssl.public_endpoints.api_key | indent(width=18, first=True) }}
          hosts:
            default: nova-novncproxy
            public:
              host: novncproxy
              tls:
                ca: |
{{ spec.features.ssl.public_endpoints.ca_cert | indent(width=18, first=True) }}
                crt: |
{{ spec.features.ssl.public_endpoints.api_cert | indent(width=18, first=True) }}
                key: |
{{ spec.features.ssl.public_endpoints.api_key | indent(width=18, first=True) }}
          port:
            novnc_proxy:
              default: 6080
              public: 443
          scheme:
            default: http
            public: https
        compute_metadata:
          host_fqdn_override:
            public:
              host: metadata.{{ spec.public_domain_name }}
              tls:
                ca: |
{{ spec.features.ssl.public_endpoints.ca_cert | indent(width=18, first=True) }}
                crt: |
{{ spec.features.ssl.public_endpoints.api_cert | indent(width=18, first=True) }}
                key: |
{{ spec.features.ssl.public_endpoints.api_key | indent(width=18, first=True) }}
          hosts:
            default: nova-metadata
            public:
              host: metadata
              tls:
                ca: |
{{ spec.features.ssl.public_endpoints.ca_cert | indent(width=18, first=True) }}
                crt: |
{{ spec.features.ssl.public_endpoints.api_cert | indent(width=18, first=True) }}
                key: |
{{ spec.features.ssl.public_endpoints.api_key | indent(width=18, first=True) }}
          port:
            metadata:
              default: 8775
              public: 443
          scheme:
            default: http
            public: https
{%- if ceph_enabled %}
      ceph_client:
        configmap: rook-ceph-config
        user_secret_name: {{ ceph.nova.secrets }}
{%- endif %}
      conf:
        policy.d:
          01-controller-default.yaml: {{ service_policy }}
          02-custom.yaml: {{ spec.get("features", {}).get("policies", {}).get("nova", {}) }}
        ceph:
{%- if ceph_enabled %}
          enabled: true
          cinder:
            user: {{ ceph.nova.username }}
            keyring: {{ ceph.nova.keyring }}
{%- else %}
          enabled: false
{%- endif %}
        nova:
          DEFAULT:
            # TODO(ohryhorov): set default availability zone to schedule instances
            # to regular computes if AZ is not set in case of advanced computes are
            # deployed as well.
            default_schedule_zone: nova
            allow_resize_to_same_host: true
{%- if signature.enabled %}
          glance:
            verify_glance_signatures: true
            enable_certificate_validation: {{ signature.get("certificate_validation", false) }}
{%- endif %}
          cache:
            backend: oslo_cache.memcache_pool
          keystone_authtoken:
            memcache_security_strategy: ENCRYPT
            memcache_secret_key: {{ credentials.memcached }}
          ironic:
            memcache_security_strategy: ENCRYPT
            memcache_secret_key: {{ credentials.memcached }}
          cinder:
            # TODO(vsaienko): remove service_name when queens support is dropped.
            catalog_info: volumev3:cinderv3:internalURL
          neutron:
            metadata_proxy_shared_secret: {{ metadata_secret }}
{%- if 'metering' in spec.features.services %}
          notifications:
            notify_on_state_change: vm_and_task_state
{%- endif %}
{%- if ephemeral_encryption.get("enabled", false) %}
          ephemeral_storage_encryption:
            enabled: true
            cipher: {{ ephemeral_encryption.get("cipher", "aes-xts-plain64") }}
            key_size: {{ ephemeral_encryption.get("key_size", 256) }}
{%- endif %}
{%- if neutron_backend == 'tungstenfabric' %}
          compute:
            live_migration_wait_for_vif_plug: false
          workarounds:
            skip_migration_revert_events: true
          os_vif_contrail_vrouter:
            vrouter_port: {{ vrouter_port }}
{%- else %}
          os_vif_ovs:
            isolate_vif: true
{%- endif %}
          libvirt:
            cpu_mode: custom
            cpu_model: kvm64
            virt_type: kvm
            rbd_user: {{ ceph.nova.username }}
{%- if spec.get('features', {}).get('nova', {}).get('images', {}).get('backend') == 'ceph' %}
            images_type: rbd
{%- elif spec.get('features', {}).get('nova', {}).get('images', {}).get('backend') == 'local' %}
            images_type: qcow2
{%- elif spec.get('features', {}).get('nova', {}).get('images', {}).get('backend') == 'lvm' %}
            images_type: lvm
            images_volume_group: {{ spec.get('features', {}).get('nova', {}).get('images', {}).get('lvm', {}).get("volume_group", "nova-vol") }}
{%- endif %}
{%- for pools, pools_config in ceph.nova.pools.items() %}
            images_rbd_pool: {{ pools_config.name }}
{%- endfor %}
          oslo_messaging_notifications:
            topics: {{ notification_topics|join(',') }}
          service_user:
            send_service_user_token: true
      {%- if baremetal_enabled %}
        nova_ironic:
          DEFAULT:
            compute_driver: ironic.IronicDriver
            reserved_host_memory_mb: 0
            reserved_host_cpu: 0
            reserved_host_disk_mb: 0
          filter_scheduler:
            track_instance_changes: false
          scheduler:
            discover_hosts_in_cells_interval: 120
      {%- endif %}
        logging:
          logger_nova:
            level: {{ spec.get('features', {}).get('logging', {}).get('nova', {}).get('level', 'INFO') }}
        {%- if spec.get('features', {}).get('nova', {}).get('live_migration_interface') %}
        libvirt:
          live_migration_interface: {{ spec.features.nova.live_migration_interface }}
        hypervisor:
          host_interface: {{ spec.features.nova.live_migration_interface }}
        {%- endif %}
        ssh_private: |
          {{ ssh_credentials.private|indent(10)|trim }}
        ssh_public: |
          {{ ssh_credentials.public }}
      network:
        core_plugin: {{ neutron_backend }}
        {%- if neutron_backend == 'tungstenfabric' %}
        backend: []
        {%- endif %}
        sshd:
          enabled: true
      jobs:
{% include 'base/_ks_jobs.yaml' %}
{%- if nova_db_cleanup.enabled %}
        db_purge:
          enabled: {{ nova_db_cleanup.enabled }}
          cron: {{ nova_db_cleanup.get("schedule", "1 0 * * 1") }}
          script:
            config:
              age: {{ nova_db_cleanup.get("age", 30) }}
              max_rows: {{ nova_db_cleanup.get("max_rows", 1000) }}
{%- endif %}
{%- endif %}
